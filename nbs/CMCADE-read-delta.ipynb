{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf79ce1d-5d4a-4d50-9fb2-4cb8b33ccaa1",
   "metadata": {},
   "source": [
    "# CMC ADE -- read data from Delta Lake tables\n",
    "`FR`\n",
    "Le présent notebook montre les façons d'interagir avec des données au format [Delta Lake](https://delta-io.github.io/delta-rs/).\n",
    "\n",
    "`EN`\n",
    "This notebook shows how to manipulate [Delta Lake](https://delta-io.github.io/delta-rs/) tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6a607-5fd3-4399-b471-0af8ec9a4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from datetime import date\n",
    "import os\n",
    "import pathlib\n",
    "import tarfile\n",
    "import time\n",
    "import daft\n",
    "import deltalake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import pyarrow as pa\n",
    "from deltalake import DeltaTable  # S3FileSystem ??\n",
    "from deltalake.writer import write_deltalake\n",
    "from tabulate import tabulate\n",
    "from tqdm.notebook import tqdm\n",
    "# opt.maxBytes = 131072\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.pandas # Won't be needed hopefully; we'll be using Polars\n",
    "import hvplot.polars\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "# hvplot.extension(\"plotly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5913e19-9ff0-4cbc-a5e1-13c882c4ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_tables import GT, md, html, style, loc\n",
    "from great_tables.data import airquality, islands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908cbe34-c444-41de-b006-5993963b950a",
   "metadata": {},
   "source": [
    "`EN` Open the Delta Table with Polars and test the various Delta tables (see `CMCADE-ingest.ipynb`) \n",
    "- `tar_swob_no_optimization` : dataframes written (then appended) without partitioning\n",
    "\n",
    "`FR` À venir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f145217-c915-482e-b01a-f1048712ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_plain = pl.scan_delta(\"tar_swob_no_optimization\").collect()\n",
    "bad_data = delta_plain.count()['name'] - delta_plain.count()['value']\n",
    "min_date = delta_plain['date_tm'].min()\n",
    "max_date = delta_plain['date_tm'].max()\n",
    "\n",
    "print(f\"Minimum Date: {min_date}\")\n",
    "print(f\"Maximum Date: {max_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7a7a2-5baf-4546-8cce-62cab6d2b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_delta_plain = pl.scan_delta(\"tar_swob_no_optimization\")\n",
    "scan_delta_by_stn_plain = pl.scan_delta(\"tar_swob_P_by_stn_name\")\n",
    "\n",
    "storage_options = {\"partition_by\": \"stn_nam\"}\n",
    "scan_delta_by_stn_arg = pl.scan_delta(\"tar_swob_P_by_stn_name\", storage_options=storage_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d03797-e113-43da-bf02-f8628f94d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7f134-25a6-43d3-b364-25a2a24e8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl_airquality = pl.DataFrame(airquality_mini).select(\n",
    "#     \"Year\", \"Month\", \"Day\", \"Ozone\", \"Solar_R\", \"Wind\", \"Temp\"\n",
    "# )\n",
    "bad_values = str(bad_data[0])\n",
    "gt_air = GT(delta_plain.count())\n",
    "(\n",
    "    gt_air\n",
    "    .fmt_integer(columns = delta_plain.columns, sep_mark=\" \",)\n",
    "    \n",
    "    # Table header ----\n",
    "    .tab_header(\n",
    "        title = \"CMC weather observations data counts\",\n",
    "        subtitle = f\"Between {min_date} and {max_date} (inclusive); Bad data values = {bad_values}\"\n",
    "    )\n",
    "    \n",
    "    # Table styles ----\n",
    "    .tab_style(\n",
    "        style.fill(\"lightgray\"),\n",
    "        loc.body(\n",
    "            columns = cs.all()\n",
    "        )\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae137174-d33a-4fa4-aae5-e6aeb2eff11c",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "\n",
    "Just as easy as an Excel formula :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2f8be-01be-45e3-9c6f-05b338556283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing query\n",
    "# Define the start and end dates; will be used for the graph title\n",
    "start_date = date(2024, 3, 4)\n",
    "end_date = date(2024, 3, 25)\n",
    "\n",
    "basic_query_read = (\n",
    "    #pl.read_delta(\"tar_swob_no_optimization\") # NO PLANNING AHEAD\n",
    "    pl.read_delta(\"tar_swob_P_by_stn_name\") # NO PLANNING AHEAD\n",
    "    .filter(pl.col(\"name\") == \"air_temp\")\n",
    "#    .filter(pl.col(\"stn_nam\") == \"STE-FOY (U. LAVAL)\")\n",
    "    .filter(pl.col(\"stn_nam\").is_in([\"STE-FOY (U. LAVAL)\", \"MALAHAT\", \"ABEE AGDM\", \"ALDERSVILLE\"]))\n",
    "#  .filter(pl.col(\"stn_nam\").is_in(stn_nam_list))\n",
    "    .filter(pl.col(\"date_tm\").is_between(start_date, end_date))\n",
    "    .sort(pl.col([\"date_tm\",\"stn_nam\"]), descending=False)\n",
    "#    .with_column(\n",
    "#        (pl.col(\"value\").max() - pl.col(\"value\").mean()).alias(\"difference\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548dc227-2ae3-496f-9277-d619a6923161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing query\n",
    "# Define the start and end dates; will be used for the graph title\n",
    "start_date = date(2024, 3, 4)\n",
    "end_date = date(2024, 3, 25)\n",
    "\n",
    "storage_options = {\"partition_by\": \"stn_nam\"}\n",
    "\n",
    "basic_query_read = (\n",
    "    #pl.scan_delta(\"tar_swob_P_by_stn_name\") \n",
    "    pl.scan_delta(\"tar_swob_P_by_stn_name\", storage_options=storage_options)\n",
    "    .filter(pl.col(\"name\") == \"air_temp\")\n",
    "    .filter(pl.col(\"stn_nam\") == \"STE-FOY (U. LAVAL)\")\n",
    "#   .filter(pl.col(\"stn_nam\").is_in([\"STE-FOY (U. LAVAL)\", \"MALAHAT\", \"ABEE AGDM\", \"ALDERSVILLE\"]))\n",
    "#  .filter(pl.col(\"stn_nam\").is_in(stn_nam_list))\n",
    "    .filter(pl.col(\"date_tm\").is_between(start_date, end_date))\n",
    "    .sort(pl.col([\"date_tm\",\"stn_nam\"]), descending=False)\n",
    "    .collect()\n",
    "#    .with_column(\n",
    "#        (pl.col(\"value\").max() - pl.col(\"value\").mean()).alias(\"difference\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ad04c-014a-4796-97d2-9de094ede970",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_query_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739f971-971f-4ff5-97e4-39f91b0c4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_delta_plain = pl.scan_delta(\"tar_swob_no_optimization\")\n",
    "scan_delta_by_stn_plain = pl.scan_delta(\"tar_swob_P_by_stn_name\")\n",
    "\n",
    "storage_options = {\"partition_by\": \"stn_nam\"}\n",
    "scan_delta_by_stn_arg = pl.scan_delta(\"tar_swob_P_by_stn_name\", storage_options=storage_options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e09ca-ba1b-46ae-9e51-dd92d09467f6",
   "metadata": {},
   "source": [
    "# Aggregating\n",
    "\n",
    "Add columns dynamically \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef69dd0-3883-4cb6-952e-7a06991403ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column showing the difference between the max and mean over a time period\n",
    "start_date = date(2024, 3, 4)\n",
    "end_date = date(2024, 3, 25)\n",
    "\n",
    "basic_query_read_ag = (\n",
    "    pl.read_delta(\"tar_swob_no_optimization\")\n",
    "    .filter(pl.col(\"name\") == \"air_temp\")\n",
    "   .filter(pl.col(\"stn_nam\") == \"STE-FOY (U. LAVAL)\")\n",
    "#    .filter(pl.col(\"stn_nam\").is_in([\"STE-FOY (U. LAVAL)\", \"MALAHAT\", \"ABEE AGDM\", \"ALDERSVILLE\"]))\n",
    "#  .filter(pl.col(\"stn_nam\").is_in(stn_nam_list))\n",
    "    .filter(pl.col(\"date_tm\").is_between(start_date, end_date))\n",
    "    .sort(pl.col([\"date_tm\",\"stn_nam\"]), descending=False)\n",
    "    .select(pl.col(\"value\").mean())\n",
    "#    .with_column(\n",
    "#        (pl.col(\"value\").max() - pl.col(\"value\").mean()).alias(\"difference\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43967c5-43f5-4f4e-a407-4e6213777b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_query_read_ag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd5295-a961-41be-bfbc-518fa24ddca5",
   "metadata": {},
   "source": [
    "# Power of Polars\n",
    "\n",
    "Case of parquet, but even better on Delta Lake tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d98640-541e-41d0-b0a5-0018aecb8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    pl.scan_parquet(\"yellow_tripdata_2023-01.parquet\")\n",
    "    .join(pl.scan_csv(\"taxi_zone_lookup.csv\"), left_on=\"PULocationID\", right_on=\"LocationID\")\n",
    "    .filter(pl.col(\"total_amount\") > 25)\n",
    "    .group_by(\"Zone\")\n",
    "    .agg(\n",
    "        (pl.col(\"total_amount\") /\n",
    "        (pl.col(\"tpep_dropoff_datetime\") - pl.col(\"tpep_pickup_datetime\")).dt.total_minutes()\n",
    "        ).mean().alias(\"cost_per_minute\")\n",
    "    ).sort(\"cost_per_minute\",descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7882d760-1094-4a61-bae5-0e7f0fb6489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4f472-f675-491f-a715-031b22ba4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_query_read_ag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb1d5b-40a1-4c50-9982-ec1fb8a4ceb5",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6539ed-c1ae-488c-87c2-c13da49dd3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the DataFrame using hvplot\n",
    "hvplot.extension(\"bokeh\")\n",
    "# hvplot.extension(\"plotly\")\n",
    "# hvplot.extension(\"matplotlib\")\n",
    "plot = basic_query_read.hvplot.line(x='date_tm', \n",
    "                                    y='value', \n",
    "                                    by='stn_nam', \n",
    "                                    title=f\"Air Temperature between {start_date} and {end_date}\")\n",
    "\n",
    "# Set the y-axis label to include the 'uom' value\n",
    "# Assuming 'uom' is a constant value for all rows in your filtered DataFrame\n",
    "uom = \"°C\" # This should be dynamically fetched if it varies\n",
    "plot.opts(ylabel=f\"Temperature ({uom})\")\n",
    "plot.opts(xlabel=f\"Date J/MM\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19e926-c456-4ffd-a62a-670775acacf5",
   "metadata": {},
   "source": [
    "# Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994708a5-511c-47a7-8e8c-528b398200b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the DataFrame using hvplot\n",
    "hvplot.extension(\"bokeh\")\n",
    "# hvplot.extension(\"plotly\")\n",
    "# hvplot.extension(\"matplotlib\")\n",
    "plot = basic_query_read.hvplot.line(x='date_tm', \n",
    "                                    y='value', \n",
    "                                    by='stn_nam', \n",
    "                                    title=f\"Air Temperature between {start_date} and {end_date}\")\n",
    "\n",
    "# Set the y-axis label to include the 'uom' value\n",
    "# Assuming 'uom' is a constant value for all rows in your filtered DataFrame\n",
    "uom = \"°C\" # This should be dynamically fetched if it varies\n",
    "plot.opts(ylabel=f\"Temperature ({uom})\")\n",
    "plot.opts(xlabel=f\"Date J/MM\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea828bea-853c-473c-aae7-b355b0484c12",
   "metadata": {},
   "source": [
    "# Geo use case\n",
    "If instead of specifying a list of station names we had a map that would allow selecting stations\n",
    "by some geo-specific query, e.g. all stations within an arbitrary polygon ?\n",
    "\n",
    "We'll keep this example simple.  Since we have data in `degrees` I will ask for all stations that \n",
    "fall within a radius of a point.  In my case, the point will be the city of Vancouver.\n",
    "\n",
    "In a real world application we would propose the user with a way to supply a range in a decent distance dimension (e.g. kilometers)\n",
    "\n",
    "What we want is to replace the list in\n",
    "\n",
    "` .filter(pl.col(\"stn_nam\").is_in([\"STE-FOY (U. LAVAL)\", \"MALAHAT\", \"ABEE AGDM\", \"ALDERSVILLE\"])) `\n",
    "\n",
    "above with a list of names coming from our buffer (see below)\n",
    "\n",
    "`[\"DELTA BURNS BOG\", \"POINT ATKINSON\", \"VANCOUVER HARBOUR CS\", \"VANCOUVER SEA ISLAND CCG\", \"WEST VANCOUVER AUT\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41150fc-993e-429c-a813-52eef094f044",
   "metadata": {},
   "source": [
    "# Create geo dataframe\n",
    "\n",
    "We first take the first occurrence of each station name and corresponding lat, long\n",
    "\n",
    "We could save as GeoJSON, but for this notebook we'll just keep the geo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc8796-a729-49e6-b02b-277632cc96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_loc_df = delta_plain.unique(subset=['stn_nam'], keep='first').sort(\"stn_nam\").select(['stn_nam', 'lat', 'long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827d980-8a28-4af2-83bc-ec91f992f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_loc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53767548-ce57-4303-9b6d-e6686e53acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(stn_loc_df['long'], stn_loc_df['lat'])]\n",
    "\n",
    "#geo_df = gpd.GeoDataFrame(stn_loc_df, geometry=geometry)\n",
    "geo_df = gpd.GeoDataFrame(stn_loc_df[['stn_nam']], geometry=geometry)\n",
    "\n",
    "# Assuming geo_df is your GeoDataFrame\n",
    "geo_df.rename(columns={0: 'stn_nam'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c879d-fd76-494d-9235-4ab95cd5398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as GeoJSON\n",
    "# geo_df.to_file(\"obs-stations.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346299aa-5175-40ab-8e24-cae4c8615e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a5cea5-b969-4959-bd3d-e5cdea847844",
   "metadata": {},
   "source": [
    "# Determine a point of interest and find all stations within a radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f604e721-58b6-48d6-8604-8015d44a04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming geo_df is your GeoDataFrame with 'stn_nam' and 'geometry' columns\n",
    "# Define the point of interest (latitude, longitude)\n",
    "# In our case, Vancouver -123.1139456, 49.2604134\n",
    "point_of_interest = Point(-123.1139456, 49.2604134)\n",
    "\n",
    "# Create a buffer around the point of interest in degrees\n",
    "# Note: This is a simplification and might not accurately represent a real-world distance\n",
    "buffer_distance_in_degrees = 0.2 # Example buffer distance in degrees\n",
    "buffer = point_of_interest.buffer(buffer_distance_in_degrees)\n",
    "\n",
    "# Convert the buffer to a GeoDataFrame\n",
    "buffer_gdf = gpd.GeoDataFrame(geometry=[buffer], crs=geo_df.crs)\n",
    "\n",
    "# Perform a spatial join to find all stations within the buffer\n",
    "stations_within_buffer = gpd.sjoin(geo_df, buffer_gdf, how='inner', predicate='within')\n",
    "\n",
    "# Print the stations within the buffer\n",
    "print(stations_within_buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd6d855-4004-4c11-9dd4-79a6d1547c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive the list of station names from the geo dataframe and visualize as per above\n",
    "stn_nam_list = stations_within_buffer['stn_nam'].values.tolist()\n",
    "\n",
    "# Print the list of station names\n",
    "print(stn_nam_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dde1b9-2803-4c60-b0b1-6e9820af864a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas_polars_daft_deltalake",
   "language": "python",
   "name": "pandas_polars_daft_deltalake"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
